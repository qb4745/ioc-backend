
---

## üìà M√©tricas y Performance

### v2 (Gemini 2.0 Flash)
- **Tiempo promedio:** 8-12 segundos
- **Tokens input:** ~3,500-5,500 (dependiendo del dashboard)
- **Tokens output:** ~1,500-3,000
- **Total tokens:** ~5,000-8,500

### v2 (Gemini 2.5 Flash con Thinking)
- **Tiempo promedio:** 12-20 segundos
- **Tokens input:** ~3,500-5,500
- **Tokens thinking:** ~1,000-2,000 (interno)
- **Tokens output:** ~2,000-4,000
- **Total tokens:** ~6,500-11,500

### v3 (Streaming)
- **Tiempo primer chunk:** ~500ms-2s
- **Tiempo total:** Similar a v2
- **Ventaja:** Percepci√≥n de velocidad mucho mejor
- **Tokens:** Mismos que v2

---

## üîí Seguridad

### Autenticaci√≥n
- Requiere token JWT v√°lido
- Verificaci√≥n de acceso al dashboard antes de generar explicaci√≥n

### Rate Limiting
- 5 requests por minuto por usuario
- Protecci√≥n contra abuso del endpoint
- Implementado con Resilience4j

### Validaci√≥n de Input
```java
@Valid @RequestBody DashboardExplanationRequest request
```

**Validaciones:**
- `dashboardId` requerido (integer)
- `fechaInicio` y `fechaFin` en formato ISO 8601
- `filtros` opcional (Map)

---

## üìù Logging

### Niveles de Log

**INFO:**
- Inicio de request: modelo, longitud de prompt
- √âxito de llamada: duraci√≥n, longitud de respuesta

**DEBUG:**
- Prompt completo enviado a Gemini
- Respuesta completa de Gemini
- JSON limpio despu√©s de `cleanGeminiJsonErrors()`

**WARN:**
- Fallos en obtenci√≥n de datos de cards
- Retries de llamadas a Gemini

**ERROR:**
- Bloqueos por safety filters con `finishReason`
- Errores de parsing JSON
- Timeouts de Gemini
- Rate limits excedidos

**TRACE:**
- Chunks incompletos en streaming (normal)

### Ejemplo de Logs

```
INFO: Calling Gemini API - Prompt length: 12450 chars, model: gemini-2.5-flash
INFO: FULL PROMPT: [contenido del prompt]
INFO: Gemini API call successful - Duration: 15234ms, Response length: 3611 chars
DEBUG: Full Gemini response: {"candidates":[...]}
DEBUG: Cleaned JSON for parsing: {"resumenEjecutivo":"..."}
```

---

## üöÄ Deployment

### Variables de Entorno Requeridas

```bash
# Gemini API
GEMINI_API_KEY=your_api_key_here

# Opcional - Configuraci√≥n avanzada
GEMINI_MODEL=gemini-2.5-flash
GEMINI_MAX_OUTPUT_TOKENS=8192
GEMINI_TIMEOUT_SECONDS=90
```

### Docker

```dockerfile
ENV GEMINI_API_KEY=${GEMINI_API_KEY}
ENV GEMINI_MODEL=gemini-2.5-flash
ENV GEMINI_MAX_OUTPUT_TOKENS=8192
```

### Configuraci√≥n Producci√≥n

```properties
# application-prod.properties
gemini.model=gemini-2.5-flash
gemini.max-output-tokens=8192
gemini.timeout.seconds=120

# Rate limiting m√°s estricto
resilience4j.ratelimiter.instances.aiExplanation.limit-for-period=3
resilience4j.ratelimiter.instances.aiExplanation.limit-refresh-period=60s
```

---

## üêõ Troubleshooting

### Error: MAX_TOKENS

**S√≠ntoma:** `Content blocked by Gemini safety filters. Reason: MAX_TOKENS`

**Soluci√≥n:**
```properties
gemini.max-output-tokens=16384  # Aumentar a 16K
```

### Error: No parts in response

**S√≠ntoma:** `No parts in Gemini response. FinishReason: SAFETY`

**Soluci√≥n:** Verificar que las 4 categor√≠as de safety est√©n en `BLOCK_NONE`

### Error: Timeout

**S√≠ntoma:** `Gemini API request timed out`

**Soluci√≥n:**
```properties
gemini.timeout.seconds=120  # Aumentar timeout
```

### Warnings en Streaming

**S√≠ntoma:** `WARN: Failed to parse stream chunk`

**Soluci√≥n:** Esto fue resuelto cambiando a `log.trace()` - ya no deber√≠as ver estos warnings

### JSON Mal Formado

**S√≠ntoma:** `JsonMappingException: Unexpected close marker`

**Soluci√≥n:** El m√©todo `cleanGeminiJsonErrors()` lo repara autom√°ticamente

---

## üìö Recursos Adicionales

### Documentaci√≥n Creada

- **AI_STREAMING_V3_GUIDE.md** - Gu√≠a completa del endpoint v3 con ejemplos
- **GEMINI_SAFETY_FILTERS_FIX.md** - Fix para bloqueos de contenido
- **GEMINI_MAX_TOKENS_FIX.md** - Soluci√≥n para error MAX_TOKENS

### APIs Externas Utilizadas

- **Google Gemini API:** https://ai.google.dev/api
- **Metabase API:** Documentaci√≥n interna del proyecto

### Librer√≠as Frontend Recomendadas

- `@microsoft/fetch-event-source` - Cliente SSE para fetch API
- `eventsource` - Polyfill para navegadores antiguos

---

## ‚úÖ Checklist de Implementaci√≥n Completa

### Backend
- ‚úÖ Endpoint v2 con respuesta JSON completa
- ‚úÖ Endpoint v3 con Server-Sent Events (streaming)
- ‚úÖ Soporte para Gemini 2.0 y 2.5 Flash
- ‚úÖ ThinkingConfig autom√°tico para Gemini 2.5
- ‚úÖ Filtros de seguridad completos (4 categor√≠as)
- ‚úÖ Limpieza autom√°tica de JSON mal formado (v2)
- ‚úÖ Manejo robusto de chunks fragmentados (v3)
- ‚úÖ Rate limiting (5 req/min)
- ‚úÖ Logging detallado con niveles apropiados
- ‚úÖ Manejo de errores con finishReason
- ‚úÖ Configuraci√≥n externalizada en properties
- ‚úÖ Tests de compilaci√≥n exitosos

### Configuraci√≥n
- ‚úÖ `application.properties` con valores por defecto
- ‚úÖ Variables de entorno documentadas
- ‚úÖ Soporte para m√∫ltiples modelos
- ‚úÖ Timeouts configurables
- ‚úÖ Tokens de salida configurables

### Documentaci√≥n
- ‚úÖ Gu√≠a de uso v3 (AI_STREAMING_V3_GUIDE.md)
- ‚úÖ Fix para safety filters (GEMINI_SAFETY_FILTERS_FIX.md)
- ‚úÖ Fix para MAX_TOKENS (GEMINI_MAX_TOKENS_FIX.md)
- ‚úÖ Informe completo para agente IA (este documento)

### Pendiente (Frontend)
- ‚è≥ Implementar consumo de v2 en React
- ‚è≥ Implementar consumo de v3 con SSE en React
- ‚è≥ UI para mostrar streaming de texto
- ‚è≥ Manejo de errores en frontend
- ‚è≥ Indicadores de carga

---

## üéØ Pr√≥ximos Pasos Recomendados

1. **Frontend v3 (Alta Prioridad)**
   - Implementar componente React para SSE
   - Agregar animaci√≥n de "typing" para mejor UX
   - Bot√≥n de cancelar stream

2. **Optimizaciones Backend**
   - Cache de respuestas recientes (Redis/Caffeine)
   - Compresi√≥n de prompts largos
   - M√©tricas con Prometheus

3. **Features Adicionales**
   - Comparaci√≥n entre periodos
   - Alertas autom√°ticas basadas en IA
   - Exportaci√≥n de explicaciones a PDF

4. **Testing**
   - Tests unitarios para `GeminiApiClient`
   - Tests de integraci√≥n para endpoints
   - Tests E2E con frontend

---

## üìû Contacto y Soporte

**Equipo:** IOC Backend Development  
**Proyecto:** Inteligencia Operacional Cambiaso  
**Versi√≥n:** 1.0.0  
**√öltima actualizaci√≥n:** 27 de Noviembre de 2025

---

**Fin del Informe**

Este documento sirve como referencia completa para cualquier agente de IA o desarrollador que necesite entender la implementaci√≥n de los endpoints v2 y v3 de explicaci√≥n de dashboards con IA.
# Informe Completo: Endpoints AI v2 y v3 - Dashboard Explanation

**Fecha:** 27 de Noviembre de 2025  
**Proyecto:** IOC Backend - Inteligencia Operacional Cambiaso  
**Feature:** Explicaci√≥n de Dashboards con IA (Gemini)

---

## üìã Resumen Ejecutivo

Se implementaron **dos versiones** del endpoint de explicaci√≥n de dashboards con IA:

- **v2**: Endpoint tradicional que retorna respuesta JSON completa
- **v3**: Endpoint moderno con **Server-Sent Events (SSE)** para streaming en tiempo real

Ambas versiones utilizan **Google Gemini API** (modelos 2.0 y 2.5 Flash) para generar an√°lisis ejecutivos de dashboards de Metabase.

---

## üéØ Endpoints Implementados

### Endpoint v2 (Respuesta Completa)

```
POST /api/v2/ai/explain-dashboard
POST /api/v2/ai/explain        (alias)
Content-Type: application/json
```

**Request:**
```json
{
  "dashboardId": 5,
  "fechaInicio": "2025-01-01",
  "fechaFin": "2025-01-31",
  "filtros": {}
}
```

**Response:**
```json
{
  "resumenEjecutivo": "Texto de 2-3 l√≠neas con estado general...",
  "keyPoints": [
    "Punto clave 1 con m√©tricas",
    "Punto clave 2 con m√©tricas",
    "Punto clave 3 con m√©tricas"
  ],
  "insightsAccionables": [
    "Recomendaci√≥n 1",
    "Recomendaci√≥n 2"
  ],
  "alertas": [
    "Alerta cr√≠tica si existe"
  ],
  "dashboardId": 5,
  "dashboardName": "Dashboard Anal√≠tico IOC",
  "fechaInicio": "2025-01-01",
  "fechaFin": "2025-01-31",
  "filtros": {},
  "generatedAt": "2025-11-27T22:44:01.219Z",
  "cached": false,
  "tokensUsed": 0,
  "durationSeconds": 20
}
```

**Caracter√≠sticas:**
- ‚úÖ Tiempo de respuesta: ~8-20 segundos
- ‚úÖ Respuesta JSON completa en un solo request
- ‚úÖ M√°s simple de implementar en frontend
- ‚úÖ Compatible con Gemini 2.0 y 2.5 Flash

---

### Endpoint v3 (Streaming SSE)

```
POST /api/v3/ai/explain-dashboard-stream
POST /api/v3/ai/explain-stream              (alias)
Content-Type: application/json
Produces: text/event-stream
```

**Request:**
```json
{
  "dashboardId": 5,
  "fechaInicio": "2025-01-01",
  "fechaFin": "2025-01-31",
  "filtros": {}
}
```

**Response (Server-Sent Events):**
```
event: message
data: {"resumenEjecutivo":"En el periodo analizado

event: message
data:  se observa un crecimiento del 15%

event: message
data:  en las m√©tricas clave...

event: done
data: [DONE]
```

**Caracter√≠sticas:**
- ‚úÖ Respuesta **incremental** en tiempo real
- ‚úÖ Mejor UX - el usuario ve texto aparecer mientras se genera
- ‚úÖ Usa `streamGenerateContent` de Gemini
- ‚úÖ Menor sensaci√≥n de tiempo de espera
- ‚úÖ Compatible con cancelaci√≥n de stream

---

## üèóÔ∏è Arquitectura Implementada

### Componentes v2

```
AiExplanationControllerV2
    ‚Üì
DynamicDashboardExplanationService
    ‚Üì (obtiene datos)
MetabaseApiClient
    ‚Üì (genera explicaci√≥n)
GeminiApiClient (generateContent)
    ‚Üì
parseResponse() ‚Üí cleanGeminiJsonErrors()
    ‚Üì
DashboardExplanationResponse
```

### Componentes v3

```
AiExplanationControllerV3
    ‚Üì
StreamingDashboardExplanationService
    ‚Üì (obtiene datos)
MetabaseApiClient
    ‚Üì (genera explicaci√≥n streaming)
StreamingGeminiApiClient (streamGenerateContent)
    ‚Üì
Flux<ServerSentEvent<String>>
    ‚Üì
Frontend (recibe chunks en tiempo real)
```

---

## üìÅ Archivos Implementados

### Controllers

**`AiExplanationControllerV2.java`**
```java
@RestController
@RequestMapping("/api/v2/ai")
public class AiExplanationControllerV2 {
    
    @PostMapping(path = { "/explain", "/explain-dashboard" })
    @RateLimiter(name = "aiExplanation")
    public ResponseEntity<DashboardExplanationResponse> explainDashboard(
            @Valid @RequestBody DashboardExplanationRequest request,
            Authentication authentication) {
        // Verificar acceso
        dashboardAccessService.checkAccessOrThrow(authentication, request.dashboardId());
        
        // Generar explicaci√≥n
        DashboardExplanationResponse response = explanationService.explainDashboard(request);
        
        return ResponseEntity.ok(response);
    }
}
```

**`AiExplanationControllerV3.java`**
```java
@RestController
@RequestMapping("/api/v3/ai")
public class AiExplanationControllerV3 {
    
    @PostMapping(path = {"/explain-dashboard-stream", "/explain-stream"}, 
                 produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    @RateLimiter(name = "aiExplanation")
    public Flux<ServerSentEvent<String>> explainDashboardStream(
            @Valid @RequestBody DashboardExplanationRequest request,
            Authentication authentication) {
        // Verificar acceso
        dashboardAccessService.checkAccessOrThrow(authentication, request.dashboardId());
        
        // Retornar stream
        return streamingExplanationService.explainDashboardStream(request);
    }
}
```

### Services

**`DynamicDashboardExplanationService.java`** (v2)
- Orquesta obtenci√≥n de datos de Metabase
- Construye prompt con system prompt + datos
- Llama a `GeminiApiClient.callGemini()`
- Parsea respuesta JSON con `cleanGeminiJsonErrors()`

**`StreamingDashboardExplanationService.java`** (v3)
- Misma l√≥gica de obtenci√≥n de datos
- Llama a `StreamingGeminiApiClient.callGeminiStream()`
- Retorna `Flux<ServerSentEvent<String>>` con chunks

### Clientes Gemini

**`GeminiApiClient.java`** (v2)
- M√©todo: `callGemini(String prompt)`
- Endpoint: `/v1beta/models/{model}:generateContent`
- Retorna: `String` (respuesta completa)
- Caracter√≠sticas:
  - ‚úÖ Timeout: 90 segundos configurable
  - ‚úÖ Retries: 2 intentos con backoff exponencial
  - ‚úÖ Manejo de errores: Rate limit, timeout, safety filters
  - ‚úÖ Parsing robusto con `extractTextFromGeminiResponse()`

**`StreamingGeminiApiClient.java`** (v3)
- M√©todo: `callGeminiStream(String prompt)`
- Endpoint: `/v1beta/models/{model}:streamGenerateContent`
- Retorna: `Flux<String>` (chunks incrementales)
- Caracter√≠sticas:
  - ‚úÖ Timeout: 90 segundos configurable
  - ‚úÖ Chunks procesados l√≠nea por l√≠nea
  - ‚úÖ Logging con `trace` (no `warn`) para chunks incompletos
  - ‚úÖ Buffer management para fragmentos JSON

---

## ‚öôÔ∏è Configuraci√≥n (application.properties)

```properties
# Modelo Gemini
gemini.model=gemini-2.5-flash
gemini.api-key=${GEMINI_API_KEY}
gemini.base-url=https://generativelanguage.googleapis.com

# Configuraci√≥n de Tokens
gemini.max-output-tokens=8192

# Timeouts
gemini.timeout.seconds=90

# Retries
gemini.retry.max-attempts=2
gemini.retry.backoff.initial=500
gemini.retry.backoff.max=1500

# Rate Limiting
resilience4j.ratelimiter.instances.aiExplanation.limit-for-period=5
resilience4j.ratelimiter.instances.aiExplanation.limit-refresh-period=60s
```

---

## üé® Caracter√≠sticas Implementadas

### 1. Soporte Multi-Modelo

| Modelo | Configuraci√≥n | Output Limit | Input Limit | Thinking |
|--------|---------------|--------------|-------------|----------|
| **gemini-2.0-flash** | `gemini.model=gemini-2.0-flash` | 8,192 tokens | 1M tokens | ‚ùå |
| **gemini-2.5-flash** | `gemini.model=gemini-2.5-flash` | 65,536 tokens | 1M tokens | ‚úÖ |

**C√≥digo de detecci√≥n autom√°tica:**
```java
boolean supportsThinking = model.contains("2.5");

String thinkingConfig = supportsThinking 
    ? """
      "thinkingConfig": {
        "thinkingBudget": -1
      },
      """
    : "";
```

### 2. Filtros de Seguridad Completos

**Problema resuelto:** Gemini bloqueaba contenido t√©cnico/industrial por filtros de seguridad.

**Soluci√≥n:** Configurar todas las 4 categor√≠as con `BLOCK_NONE`

```json
"safetySettings": [
  {
    "category": "HARM_CATEGORY_HARASSMENT",
    "threshold": "BLOCK_NONE"
  },
  {
    "category": "HARM_CATEGORY_HATE_SPEECH",
    "threshold": "BLOCK_NONE"
  },
  {
    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
    "threshold": "BLOCK_NONE"
  },
  {
    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
    "threshold": "BLOCK_NONE"
  }
]
```

### 3. Limpieza Autom√°tica de JSON Mal Formado (v2)

**Problema:** Gemini a veces genera JSON inv√°lido (arrays cerrados con `}` en lugar de `]`)

**Soluci√≥n:** M√©todo `cleanGeminiJsonErrors()` que repara autom√°ticamente:

```java
private String cleanGeminiJsonErrors(String json) {
    // Fix: "item"} ‚Üí "item"]
    json = json.replaceAll(",\\s*\"([^\"]+)\"\\s*\\}", ",\"$1\"]");
    
    // Fix: trailing commas
    json = json.replaceAll(",\\s*\\]", "]");
    json = json.replaceAll(",\\s*\\}", "}");
    
    // Remove markdown
    json = json.replace("```json", "").replace("```", "");
    
    return json.trim();
}
```

### 4. Manejo de Chunks Fragmentados (v3)

**Problema:** Streaming env√≠a JSON fragmentado que no se puede parsear chunk por chunk

**Soluci√≥n:** Cambio de `log.warn()` a `log.trace()` y procesamiento l√≠nea por l√≠nea:

```java
private Flux<String> extractTextFromStreamChunk(String chunk, StringBuilder buffer) {
    String[] lines = chunk.split("\n");
    
    return Flux.fromArray(lines)
            .filter(line -> !line.trim().isEmpty())
            .flatMap(line -> {
                try {
                    JsonNode root = objectMapper.readTree(line);
                    // Extraer texto...
                } catch (Exception e) {
                    log.trace("Skipping incomplete chunk (normal in streaming): {}", line);
                    return Flux.empty();
                }
            });
}
```

### 5. Manejo Robusto de Errores

**v2 - GeminiApiClient:**
```java
// Detectar finishReason
String finishReason = firstCandidate.path("finishReason").asText("");
if (!finishReason.isEmpty() && !finishReason.equals("STOP")) {
    log.error("Gemini blocked content. finishReason: {}, Full response: {}", 
              finishReason, response);
    
    // Log safety ratings
    JsonNode safetyRatings = firstCandidate.path("safetyRatings");
    if (!safetyRatings.isEmpty()) {
        log.error("Safety ratings: {}", safetyRatings);
    }
    
    throw new GeminiApiException(
        "Content blocked by Gemini safety filters. Reason: " + finishReason
    );
}
```

**Posibles valores de `finishReason`:**
- `STOP` ‚Üí ‚úÖ Generaci√≥n exitosa
- `SAFETY` ‚Üí ‚ö†Ô∏è Bloqueado por filtros de seguridad
- `RECITATION` ‚Üí ‚ö†Ô∏è Bloqueado por contenido con copyright
- `MAX_TOKENS` ‚Üí ‚ö†Ô∏è Se alcanz√≥ l√≠mite de tokens
- `OTHER` ‚Üí ‚ö†Ô∏è Otra raz√≥n

### 6. Rate Limiting

**Configuraci√≥n:**
- **L√≠mite:** 5 requests por minuto por usuario
- **Periodo:** 60 segundos
- **Librer√≠a:** Resilience4j

```java
@RateLimiter(name = "aiExplanation")
public ResponseEntity<DashboardExplanationResponse> explainDashboard(...) {
    // ...
}
```

---

## üîß Problemas Resueltos Durante Implementaci√≥n

### Problema 1: MAX_TOKENS con Gemini 2.5 Flash

**Error:**
```json
{
  "message": "Content blocked by Gemini safety filters. Reason: MAX_TOKENS"
}
```

**Causa:**
- Gemini 2.5 usa `thinkingConfig` que consume tokens adicionales
- Con `maxOutputTokens: 2048` no alcanzaban los tokens para thinking + respuesta

**Soluci√≥n:**
1. Aumentar `gemini.max-output-tokens` de 2048 ‚Üí 8192
2. Agregar `thinkingConfig` autom√°ticamente para modelos 2.5

### Problema 2: JSON Mal Formado

**Error:**
```
JsonMappingException: Unexpected close marker '}': expected ']'
```

**Causa:** Gemini genera JSON con errores de sintaxis

**Soluci√≥n:** M√©todo `cleanGeminiJsonErrors()` que repara autom√°ticamente

### Problema 3: Warnings Molestos en Streaming

**Error:**
```
WARN: Failed to parse stream chunk, skipping: Unexpected close marker '}'
```

**Causa:** Los chunks en streaming vienen fragmentados (esto es **normal**)

**Soluci√≥n:** Cambiar `log.warn()` a `log.trace()` para chunks incompletos

### Problema 4: Bloqueos por Safety Filters

**Error:**
```
No parts in response. FinishReason: SAFETY
```

**Causa:** Solo se configuraba 1 de 4 categor√≠as de seguridad

**Soluci√≥n:** Configurar las 4 categor√≠as con `BLOCK_NONE`

---

## üìä Comparativa v2 vs v3

| Caracter√≠stica | v2 (Completo) | v3 (Streaming) |
|----------------|---------------|----------------|
| **Tiempo respuesta** | ~8-20 segundos | Inmediato (chunks) |
| **UX** | Pantalla en blanco | Texto aparece en vivo |
| **Implementaci√≥n Frontend** | M√°s simple | M√°s complejo |
| **Tipo respuesta** | JSON √∫nico | Server-Sent Events |
| **API Gemini** | `generateContent` | `streamGenerateContent` |
| **Cancelaci√≥n** | ‚ùå | ‚úÖ |
| **Uso memoria** | Mayor (buffer completo) | Menor (streaming) |
| **Rate limit** | 5/min | 5/min |
| **Compatibilidad** | Universal | Requiere SSE |

---

## üíª Ejemplo de Uso Frontend

### v2 - Fetch tradicional

```javascript
async function explainDashboard(dashboardId, fechaInicio, fechaFin) {
  const response = await fetch('/api/v2/ai/explain-dashboard', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({
      dashboardId,
      fechaInicio,
      fechaFin,
      filtros: {}
    })
  });

  const data = await response.json();
  console.log(data.resumenEjecutivo);
  console.log(data.keyPoints);
  console.log(data.insightsAccionables);
}
```

### v3 - Streaming con Fetch API

```javascript
async function explainDashboardStreaming(dashboardId, fechaInicio, fechaFin) {
  const response = await fetch('/api/v3/ai/explain-dashboard-stream', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({
      dashboardId,
      fechaInicio,
      fechaFin,
      filtros: {}
    })
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';

  while (true) {
    const { done, value } = await reader.read();
    
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    
    // Procesar SSE
    const lines = buffer.split('\n\n');
    buffer = lines.pop();
    
    for (const line of lines) {
      if (!line.trim()) continue;
      
      const eventMatch = line.match(/^event: (.+)$/m);
      const dataMatch = line.match(/^data: (.+)$/m);
      
      if (eventMatch && dataMatch) {
        const event = eventMatch[1];
        const data = dataMatch[1];
        
        if (event === 'message') {
          // Agregar texto al UI
          appendText(data);
        } else if (event === 'done') {
          console.log('Stream complete');
          break;
        }
      }
    }
  }
}
```

### v3 - Streaming con Librer√≠a

```bash
npm install @microsoft/fetch-event-source
```

```javascript
import { fetchEventSource } from '@microsoft/fetch-event-source';

await fetchEventSource('/api/v3/ai/explain-dashboard-stream', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    dashboardId: 5,
    fechaInicio: '2025-01-01',
    fechaFin: '2025-01-31'
  }),
  onmessage(event) {
    if (event.event === 'message') {
      appendText(event.data);
    } else if (event.event === 'done') {
      console.log('Complete');
    }
  },
  onerror(err) {
    console.error('Error:', err);
    throw err;
  }
});
```

---

## üß™ Testing

### Curl Test v2

```bash
curl -X POST http://localhost:8080/api/v2/ai/explain-dashboard \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "dashboardId": 5,
    "fechaInicio": "2025-01-01",
    "fechaFin": "2025-01-31"
  }'
```

### Curl Test v3 (Streaming)

```bash
curl -N -X POST http://localhost:8080/api/v3/ai/explain-dashboard-stream \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "dashboardId": 5,
    "fechaInicio": "2025-01-01",
    "fechaFin": "2025-01-31"
  }'
```

**Nota:** La opci√≥n `-N` deshabilita buffering para ver el stream en tiempo real.

