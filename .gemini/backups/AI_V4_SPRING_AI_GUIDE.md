# üöÄ Endpoint v4 - Spring AI con Streaming Real

**Fecha:** 28 de Noviembre de 2025  
**Feature:** Explicaci√≥n de Dashboards con Spring AI y Google GenAI  
**Ventaja Principal:** Chunks reales e incrementales con soporte nativo de Spring AI

---

## üìã Resumen

La **versi√≥n 4** utiliza **Spring AI** con soporte nativo para Google GenAI, lo que proporciona:

‚úÖ **Streaming real** con chunks incrementales verdaderos  
‚úÖ **Configuraci√≥n simplificada** con auto-configuraci√≥n de Spring Boot  
‚úÖ **API m√°s limpia** - Spring AI maneja la complejidad  
‚úÖ **Mejor rendimiento** - optimizado para streaming  
‚úÖ **M√∫ltiples modelos** - f√°cil cambio entre Gemini 2.0, 2.5, etc.

---

## üéØ Endpoint v4

```
POST /api/v4/ai/explain-dashboard-stream
POST /api/v4/ai/explain-stream              (alias)
Content-Type: application/json
Produces: text/event-stream
```

### Request

```json
{
  "dashboardId": 5,
  "fechaInicio": "2025-11-01",
  "fechaFin": "2025-11-30",
  "filtros": {}
}
```

### Response (Server-Sent Events)

```
event: message
data: {"resumenEjecutivo": "Noviembre

event: message
data:  de 2025 registr√≥ una producci√≥n

event: message
data:  total de 128.087 unidades, lo que

event: message
data:  representa una disminuci√≥n del 49%...

event: done
data: [DONE]
```

---

## ‚öôÔ∏è Configuraci√≥n

### 1. Dependencias (pom.xml)

```xml
<properties>
    <spring-ai.version>1.0.0-M4</spring-ai.version>
</properties>

<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.ai</groupId>
            <artifactId>spring-ai-bom</artifactId>
            <version>${spring-ai.version}</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>

<dependencies>
    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-starter-model-google-genai</artifactId>
    </dependency>
</dependencies>
```

### 2. Application Properties

```properties
# Enable Google GenAI Chat Model
spring.ai.model.chat=google-genai

# API Key (set via environment variable)
spring.ai.google.genai.api-key=${GEMINI_API_KEY}

# Model configuration - Aligned with gemini.model property
spring.ai.google.genai.chat.options.model=gemini-2.5-flash
spring.ai.google.genai.chat.options.temperature=0.2
spring.ai.google.genai.chat.options.max-output-tokens=8192
spring.ai.google.genai.chat.options.top-p=0.95
spring.ai.google.genai.chat.options.top-k=40
```

**IMPORTANTE:** El modelo `gemini-2.5-flash` est√° alineado con la configuraci√≥n `gemini.model` usada por los endpoints v2 y v3, asegurando consistencia en toda la aplicaci√≥n.

### 3. Variable de Entorno

```bash
export GEMINI_API_KEY="your-api-key-here"
```

**Obt√©n tu API key en:** https://aistudio.google.com/app/apikey

---

## üèóÔ∏è Arquitectura

```
AiExplanationControllerV4
    ‚Üì
SpringAiDashboardExplanationService
    ‚Üì
GoogleGenAiChatModel (Spring AI)
    ‚Üì
chatModel.stream(prompt)
    ‚Üì
Flux<ChatResponse> ‚Üí Flux<ServerSentEvent<String>>
    ‚Üì
Frontend (recibe chunks reales en tiempo real)
```

### Componentes Principales

**Controller:** `AiExplanationControllerV4.java`
- Endpoint `/api/v4/ai/explain-dashboard-stream`
- Valida acceso al dashboard
- Retorna `Flux<ServerSentEvent<String>>`

**Service:** `SpringAiDashboardExplanationService.java`
- Obtiene datos de Metabase
- Construye prompt din√°mico
- Llama a Spring AI con streaming
- Convierte `ChatResponse` a SSE

**Spring AI:** `GoogleGenAiChatModel` (auto-configurado)
- Maneja conexi√≥n con Gemini API
- Procesa streaming autom√°ticamente
- Gestiona retry y error handling

---

## üíª C√≥digo del Service

```java
@Service
@Slf4j
@RequiredArgsConstructor
public class SpringAiDashboardExplanationService {

    private final GoogleGenAiChatModel chatModel;
    private final MetabaseApiClient metabaseClient;

    public Flux<ServerSentEvent<String>> explainDashboardStream(DashboardExplanationRequest request) {
        // 1. Obtener datos del dashboard
        JsonNode dashboard = metabaseClient.getDashboard(request.dashboardId());
        
        // 2. Construir prompt
        String promptText = buildDynamicPrompt(request, dashboardName, dataSummary);
        Prompt prompt = new Prompt(promptText);

        // 3. Stream con Spring AI - ¬°Chunks reales!
        return chatModel.stream(prompt)
                .map(chatResponse -> {
                    String content = extractContent(chatResponse);
                    
                    return ServerSentEvent.<String>builder()
                            .event("message")
                            .data(content)
                            .build();
                })
                .filter(sse -> !sse.data().isEmpty())
                .concatWith(Flux.just(
                        ServerSentEvent.<String>builder()
                                .event("done")
                                .data("[DONE]")
                                .build()
                ));
    }
}
```

---

## üîß Diferencias con v3

| Aspecto | v3 (Custom) | v4 (Spring AI) |
|---------|-------------|----------------|
| **Dependencia** | WebClient manual | Spring AI starter |
| **Configuraci√≥n** | Manual con properties | Auto-configuraci√≥n |
| **Cliente Gemini** | `StreamingGeminiApiClient` | `GoogleGenAiChatModel` |
| **Streaming** | Parsing manual de JSON | Nativo de Spring AI |
| **Chunks** | Acumulados (1 grande) | Incrementales (reales) |
| **Error handling** | Manual | Incluido en Spring AI |
| **C√≥digo** | ~300 l√≠neas | ~150 l√≠neas |

---

## üß™ Testing

### Curl Test

```bash
curl -N -X POST http://localhost:8080/api/v4/ai/explain-dashboard-stream \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "dashboardId": 5,
    "fechaInicio": "2025-11-01",
    "fechaFin": "2025-11-30"
  }'
```

### JavaScript (Frontend)

```javascript
import { fetchEventSource } from '@microsoft/fetch-event-source';

await fetchEventSource('/api/v4/ai/explain-dashboard-stream', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    dashboardId: 5,
    fechaInicio: '2025-11-01',
    fechaFin: '2025-11-30'
  }),
  onmessage(event) {
    if (event.event === 'message') {
      // Agregar texto incremental al UI
      appendText(event.data);
    } else if (event.event === 'done') {
      console.log('Streaming complete');
    }
  },
  onerror(err) {
    console.error('Error:', err);
  }
});
```

---

## üìä Logs Esperados

```
INFO: Generating Spring AI streaming explanation for dashboard 5
INFO: Found 15 cards in dashboard 5
INFO: Calling Spring AI Gemini with streaming - Prompt length: 8737 chars
INFO: Received chunk from Spring AI: 45 chars
INFO: Received chunk from Spring AI: 67 chars
INFO: Received chunk from Spring AI: 52 chars
INFO: Received chunk from Spring AI: 89 chars
...
INFO: Spring AI streaming completed for dashboard 5
```

**Nota:** Ver√°s **m√∫ltiples** "Received chunk" en lugar de uno solo como en v3.

---

## üé® Modelos Soportados

Spring AI soporta todos los modelos de Gemini:

```properties
# Gemini 2.0 Flash (m√°s r√°pido)
spring.ai.google.genai.chat.options.model=gemini-2.0-flash

# Gemini 2.0 Flash Lite (ultra r√°pido)
spring.ai.google.genai.chat.options.model=gemini-2.0-flash-lite

# Gemini 1.5 Flash
spring.ai.google.genai.chat.options.model=gemini-1.5-flash

# Gemini Pro
spring.ai.google.genai.chat.options.model=gemini-pro
```

---

## üîí Seguridad

### Autenticaci√≥n
- Requiere token JWT v√°lido
- Verificaci√≥n de acceso al dashboard

### Rate Limiting
```java
@RateLimiter(name = "aiExplanation")  // 5 req/min
```

### API Key
- Almacenada en variable de entorno
- Nunca en c√≥digo fuente
- Rotaci√≥n peri√≥dica recomendada

---

## ‚ö° Performance

### Tiempo de Respuesta

- **Primer chunk:** ~500ms - 2s
- **Chunks subsiguientes:** Cada ~100-500ms
- **Total:** Similar a v2/v3 pero con mejor UX

### Tama√±o de Chunks

Los chunks son **din√°micos** seg√∫n c√≥mo Gemini genera el texto:
- Chunk 1: ~40-80 caracteres
- Chunk 2: ~60-100 caracteres
- Chunk N: Variable

### Consumo de Recursos

- **Memoria:** Menor que v2/v3 (no acumula)
- **CPU:** Similar
- **Network:** Streaming eficiente

---

## üêõ Troubleshooting

### Error: "Cannot resolve GoogleGenAiChatModel"

**Soluci√≥n:**
```bash
mvn clean install -DskipTests
```

### Error: "API key not configured"

**Soluci√≥n:**
```bash
export GEMINI_API_KEY="your-key"
# O agregar a application.properties:
spring.ai.google.genai.api-key=your-key
```

### No se reciben chunks

**Verificar logs:**
```
INFO: Received chunk from Spring AI: X chars
```

Si solo ves **1 chunk**, puede ser que Gemini est√© respondiendo muy r√°pido para dashboards peque√±os.

### Stream se cierra prematuramente

**Verificar:**
- Timeout del cliente HTTP
- Configuraci√≥n de proxy/load balancer
- Keep-alive connections

---

## üìö Recursos

### Documentaci√≥n Oficial

- **Spring AI:** https://docs.spring.io/spring-ai/reference/
- **Google GenAI:** https://ai.google.dev/gemini-api/docs
- **Gemini Models:** https://ai.google.dev/gemini-api/docs/models

### Ejemplos de Spring AI

- GitHub: https://github.com/spring-projects/spring-ai
- Samples: https://github.com/spring-projects/spring-ai-examples

---

## üöÄ Pr√≥ximos Pasos

### Implementaci√≥n Frontend

1. Instalar librer√≠a SSE
   ```bash
   npm install @microsoft/fetch-event-source
   ```

2. Crear componente React para streaming
3. Agregar animaci√≥n de "typing"
4. Implementar bot√≥n de cancelar

### Optimizaciones Backend

1. **Cache con Redis**
   - Cachear respuestas completas
   - TTL de 10 minutos

2. **Compresi√≥n**
   - Comprimir prompts largos
   - Gzip en SSE

3. **M√©tricas**
   - Prometheus metrics
   - Dashboard de monitoreo

### Features Adicionales

- Comparaci√≥n entre periodos
- M√∫ltiples idiomas
- Exportaci√≥n a PDF
- Alertas autom√°ticas

---

## ‚úÖ Checklist de Migraci√≥n v3 ‚Üí v4

- [x] Agregar dependencia `spring-ai-starter-model-google-genai`
- [x] Configurar properties de Spring AI
- [x] Crear `SpringAiDashboardExplanationService`
- [x] Crear `AiExplanationControllerV4`
- [x] Configurar `GEMINI_API_KEY` en entorno
- [ ] Probar endpoint con curl
- [ ] Verificar logs de chunks m√∫ltiples
- [ ] Implementar frontend
- [ ] Deploy a producci√≥n

---

## üìù Notas Importantes

### Spring AI vs Custom Implementation

**Usa Spring AI (v4) cuando:**
- Quieres c√≥digo m√°s limpio y mantenible
- Necesitas soporte empresarial
- Planeas usar m√∫ltiples modelos de IA
- Quieres actualizaciones autom√°ticas

**Usa Custom (v3) cuando:**
- Necesitas control total del streaming
- Tienes requerimientos muy espec√≠ficos
- No quieres dependencias adicionales

### Compatibilidad

- ‚úÖ Spring Boot 3.4.x y 3.5.x
- ‚úÖ Java 21+
- ‚úÖ Todos los modelos de Gemini
- ‚úÖ API key de Google AI Studio

### Limitaciones

- Requiere API key de Google
- No funciona offline
- Sujeto a l√≠mites de rate de Gemini API
- Necesita conexi√≥n a internet estable

---

**Fin del documento**

Este endpoint v4 con Spring AI proporciona la mejor experiencia de streaming con soporte nativo, c√≥digo m√°s limpio y chunks reales e incrementales.
