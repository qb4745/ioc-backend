# Fix: Batch Inserts no funcionaban en Render (Production)

## üî¥ Problema Identificado

El batching de Hibernate NO estaba funcionando correctamente en producci√≥n (Render) debido a un **desajuste entre `batch_size` y `allocationSize`**.

### Configuraci√≥n Incorrecta:
- **FactProduction.java**: `allocationSize = 100` (secuencia)
- **application-prod.properties**: `batch_size = 500` ‚ùå

### Por qu√© esto rompe el batching:

Hibernate optimiza los batch inserts cuando `batch_size` es igual o m√∫ltiplo del `allocationSize` de la secuencia. Cuando no coinciden:

1. Hibernate pre-asigna IDs de la secuencia en bloques de `allocationSize` (100)
2. Intenta hacer batches de `batch_size` (500)
3. Al llegar al insert #100, necesita pedir m√°s IDs a la secuencia
4. Esto **rompe el batch** y fuerza un flush prematuro
5. Resultado: inserts individuales en lugar de batches

## ‚úÖ Soluci√≥n Aplicada

He cambiado el `batch_size` de **500 ‚Üí 100** en todos los archivos de properties para que coincida con el `allocationSize` de la secuencia.

### Archivos Modificados:

#### 1. `application.properties` (base)
```properties
# Antes
spring.jpa.properties.hibernate.jdbc.batch_size=500 ‚ùå

# Despu√©s
spring.jpa.properties.hibernate.jdbc.batch_size=100 ‚úÖ
spring.jpa.properties.hibernate.jdbc.fetch_size=100
```

#### 2. `application-prod.properties` (Render)
```properties
# CRITICO: batch_size debe coincidir con allocationSize de la secuencia (100)
spring.jpa.properties.hibernate.jdbc.batch_size=100
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true
spring.jpa.properties.hibernate.generate_statistics=false

spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.id.new_generator_mappings=true
spring.jpa.properties.hibernate.jdbc.fetch_size=100

spring.jpa.properties.hibernate.id.optimizer.pooled.prefer_lo=true
spring.jpa.properties.hibernate.jdbc.batch_on_entity_mapping=true
```

## üìä Configuraci√≥n Final √ìptima

| Par√°metro | Valor | Raz√≥n |
|-----------|-------|-------|
| `allocationSize` | 100 | Definido en `@SequenceGenerator` |
| `batch_size` | 100 | **Debe coincidir con allocationSize** |
| `fetch_size` | 100 | Consistencia con batch_size |
| `order_inserts` | true | Agrupa inserts por tipo de entidad |
| `order_updates` | true | Agrupa updates por tipo de entidad |

## üéØ C√≥mo Verificar que Funciona

### 1. En Logs de Render (despu√©s del deploy)

Busca l√≠neas como:
```
Hibernate: insert into fact_production (...) values (?,?,?...)
Hibernate: insert into fact_production (...) values (?,?,?...)
...
(100 inserts agrupados en un solo batch)
```

Si ves **un solo** statement de INSERT seguido de 100 l√≠neas de bindings, el batch est√° funcionando.

### 2. Monitoreo de Performance

Con batch funcionando correctamente:
- ‚úÖ Tiempo de procesamiento ETL reducido en ~70-80%
- ‚úÖ Menos round-trips a la base de datos
- ‚úÖ Menor uso de conexiones del pool

### 3. Si quieres verificar con estad√≠sticas de Hibernate

Cambia temporalmente en `application-prod.properties`:
```properties
spring.jpa.properties.hibernate.generate_statistics=true
```

Y busca en logs:
```
INFO  o.h.e.i.StatisticsInitiator - Statistics initialized [enabled=true]
...
INFO  o.h.e.i.StatisticsImpl - Batched statements executed: 100
```

## üîß Alternativas (si necesitas m√°s throughput en el futuro)

### Opci√≥n 1: Aumentar allocationSize (recomendado)

Modificar la entidad:
```java
@SequenceGenerator(
    name = "fact_production_seq",
    sequenceName = "fact_production_id_seq",
    allocationSize = 500  // Cambiar de 100 a 500
)
```

Y la secuencia en PostgreSQL:
```sql
ALTER SEQUENCE fact_production_id_seq INCREMENT BY 500;
```

Luego ajustar properties:
```properties
spring.jpa.properties.hibernate.jdbc.batch_size=500
spring.jpa.properties.hibernate.jdbc.fetch_size=500
```

### Opci√≥n 2: Usar UUID (sin secuencias)

Cambiar de SEQUENCE a UUID:
```java
@Id
@GeneratedValue(strategy = GenerationType.UUID)
private UUID id;
```

Ventajas:
- ‚úÖ No necesita secuencias
- ‚úÖ Batch size puede ser cualquier valor
- ‚úÖ IDs se generan en memoria

Desventajas:
- ‚ùå UUIDs ocupan m√°s espacio (16 bytes vs 8 bytes)
- ‚ùå √çndices menos eficientes

## üìù Notas Importantes

1. **No cambies solo el batch_size sin cambiar allocationSize**: Siempre deben estar sincronizados.

2. **El cambio de allocationSize requiere modificar la secuencia en PostgreSQL**: Si cambias allocationSize en Java, debes ejecutar:
   ```sql
   ALTER SEQUENCE fact_production_id_seq INCREMENT BY <nuevo_valor>;
   ```

3. **Con pool de 3 conexiones y batch_size=100**: Tu app puede insertar hasta 300 registros simult√°neamente (3 conexiones √ó 100 registros/batch).

4. **reWriteBatchedInserts=true en JDBC URL**: Ya lo tienes configurado, esto es CR√çTICO para que PostgreSQL realmente agrupe los inserts.

## üöÄ Deploy y Verificaci√≥n

```bash
# 1. Commit los cambios
git add src/main/resources/application*.properties
git commit -m "fix: align batch_size with allocationSize (100) for proper batch inserts"

# 2. Push a Render
git push origin main

# 3. Monitorear logs en Render
# Busca: "Batch statements executed" o grupos de inserts
```

## ‚úÖ Resultado Esperado

Con esta configuraci√≥n:
- ‚úÖ Batch inserts funcionando correctamente
- ‚úÖ ETL procesando 100 registros por batch
- ‚úÖ Pool de 3 conexiones suficiente para Supabase free tier
- ‚úÖ Performance optimizada para producci√≥n en Render

